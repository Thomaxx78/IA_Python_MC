{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data_train = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")\n",
    "\n",
    "mnist_data_test = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=T.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(mnist_data_train, batch_size=64, pin_memory=4, shuffle=True, )\n",
    "test_dataloader = DataLoader(mnist_data_test, batch_size=64, pin_memory=4, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class NeuraalNetwork(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layer1 = nn.Linear(28 * 28, 128)\n",
    "#         self.layer2 = nn.Linear(128, 128)\n",
    "#         self.layer3 = nn.Linear(128, 10)\n",
    "#         self.activation = nn.ReLU()\n",
    "#         self.flatten = nn.Flatten()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.activation(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = self.activation(x)\n",
    "#         return x\n",
    "\n",
    "class CNN3Filters(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,  out_channels=6,  kernel_size=3)  # 28 → 26\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,  out_channels=16, kernel_size=3)  # 13 → 11\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3)  # 5  → 3\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)                      # /2 chaque fois\n",
    "\n",
    "        self.fc1 = nn.Linear(32 * 1 * 1, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)      \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator() if torch.accelerator.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN3Filters().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasfilhol/Documents/A3/iaweb/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.5008\n",
      "Accuracy: 83.55%\n",
      "Test Loss: 0.1801\n",
      "Test Accuracy: 94.23%\n",
      "Test Accuracy: 94.23%\n",
      "Average Loss: 0.1620\n",
      "Accuracy: 94.95%\n",
      "Test Loss: 0.1264\n",
      "Test Accuracy: 96.00%\n",
      "Test Accuracy: 96.00%\n",
      "Average Loss: 0.1200\n",
      "Accuracy: 96.33%\n",
      "Test Loss: 0.0937\n",
      "Test Accuracy: 97.07%\n",
      "Test Accuracy: 97.07%\n",
      "Average Loss: 0.0981\n",
      "Accuracy: 96.96%\n",
      "Test Loss: 0.0882\n",
      "Test Accuracy: 97.29%\n",
      "Test Accuracy: 97.29%\n",
      "Average Loss: 0.0867\n",
      "Accuracy: 97.34%\n",
      "Test Loss: 0.0757\n",
      "Test Accuracy: 97.58%\n",
      "Test Accuracy: 97.58%\n",
      "Average Loss: 0.0755\n",
      "Accuracy: 97.61%\n",
      "Test Loss: 0.0691\n",
      "Test Accuracy: 97.82%\n",
      "Test Accuracy: 97.82%\n",
      "Average Loss: 0.0667\n",
      "Accuracy: 97.94%\n",
      "Test Loss: 0.0597\n",
      "Test Accuracy: 98.17%\n",
      "Test Accuracy: 98.17%\n",
      "Average Loss: 0.0602\n",
      "Accuracy: 98.07%\n",
      "Test Loss: 0.0724\n",
      "Test Accuracy: 97.89%\n",
      "Test Accuracy: 97.89%\n",
      "Average Loss: 0.0561\n",
      "Accuracy: 98.23%\n",
      "Test Loss: 0.0615\n",
      "Test Accuracy: 98.13%\n",
      "Test Accuracy: 98.13%\n",
      "Average Loss: 0.0531\n",
      "Accuracy: 98.34%\n",
      "Test Loss: 0.0641\n",
      "Test Accuracy: 98.11%\n",
      "Test Accuracy: 98.11%\n",
      "Average Loss: 0.0478\n",
      "Accuracy: 98.49%\n",
      "Test Loss: 0.0583\n",
      "Test Accuracy: 98.37%\n",
      "Test Accuracy: 98.37%\n",
      "Average Loss: 0.0452\n",
      "Accuracy: 98.56%\n",
      "Test Loss: 0.0882\n",
      "Test Accuracy: 97.34%\n",
      "Test Accuracy: 97.34%\n",
      "Average Loss: 0.0433\n",
      "Accuracy: 98.57%\n",
      "Test Loss: 0.0596\n",
      "Test Accuracy: 98.28%\n",
      "Test Accuracy: 98.28%\n",
      "Average Loss: 0.0389\n",
      "Accuracy: 98.80%\n",
      "Test Loss: 0.0571\n",
      "Test Accuracy: 98.37%\n",
      "Test Accuracy: 98.37%\n",
      "Average Loss: 0.0374\n",
      "Accuracy: 98.80%\n",
      "Test Loss: 0.0621\n",
      "Test Accuracy: 98.20%\n",
      "Test Accuracy: 98.20%\n",
      "Average Loss: 0.0343\n",
      "Accuracy: 98.89%\n",
      "Test Loss: 0.0621\n",
      "Test Accuracy: 98.14%\n",
      "Test Accuracy: 98.14%\n",
      "Average Loss: 0.0328\n",
      "Accuracy: 98.95%\n",
      "Test Loss: 0.0616\n",
      "Test Accuracy: 98.30%\n",
      "Test Accuracy: 98.30%\n",
      "Average Loss: 0.0305\n",
      "Accuracy: 98.98%\n",
      "Test Loss: 0.0622\n",
      "Test Accuracy: 98.31%\n",
      "Test Accuracy: 98.31%\n",
      "Average Loss: 0.0282\n",
      "Accuracy: 99.06%\n",
      "Test Loss: 0.0613\n",
      "Test Accuracy: 98.46%\n",
      "Test Accuracy: 98.46%\n",
      "Average Loss: 0.0277\n",
      "Accuracy: 99.08%\n",
      "Test Loss: 0.0582\n",
      "Test Accuracy: 98.35%\n",
      "Test Accuracy: 98.35%\n",
      "Average Loss: 0.0273\n",
      "Accuracy: 99.10%\n",
      "Test Loss: 0.0542\n",
      "Test Accuracy: 98.49%\n",
      "Test Accuracy: 98.49%\n",
      "Average Loss: 0.0230\n",
      "Accuracy: 99.25%\n",
      "Test Loss: 0.0687\n",
      "Test Accuracy: 98.36%\n",
      "Test Accuracy: 98.36%\n",
      "Average Loss: 0.0230\n",
      "Accuracy: 99.24%\n",
      "Test Loss: 0.0716\n",
      "Test Accuracy: 98.04%\n",
      "Test Accuracy: 98.04%\n",
      "Average Loss: 0.0224\n",
      "Accuracy: 99.25%\n",
      "Test Loss: 0.0593\n",
      "Test Accuracy: 98.43%\n",
      "Test Accuracy: 98.43%\n",
      "Average Loss: 0.0205\n",
      "Accuracy: 99.28%\n",
      "Test Loss: 0.0689\n",
      "Test Accuracy: 98.35%\n",
      "Test Accuracy: 98.35%\n",
      "Average Loss: 0.0191\n",
      "Accuracy: 99.34%\n",
      "Test Loss: 0.0637\n",
      "Test Accuracy: 98.44%\n",
      "Test Accuracy: 98.44%\n",
      "Average Loss: 0.0185\n",
      "Accuracy: 99.39%\n",
      "Test Loss: 0.0702\n",
      "Test Accuracy: 98.29%\n",
      "Test Accuracy: 98.29%\n",
      "Average Loss: 0.0203\n",
      "Accuracy: 99.32%\n",
      "Test Loss: 0.0755\n",
      "Test Accuracy: 98.14%\n",
      "Test Accuracy: 98.14%\n",
      "Average Loss: 0.0172\n",
      "Accuracy: 99.45%\n",
      "Test Loss: 0.0593\n",
      "Test Accuracy: 98.63%\n",
      "Test Accuracy: 98.63%\n",
      "Average Loss: 0.0159\n",
      "Accuracy: 99.45%\n",
      "Test Loss: 0.0780\n",
      "Test Accuracy: 98.38%\n",
      "Test Accuracy: 98.38%\n",
      "Average Loss: 0.0187\n",
      "Accuracy: 99.32%\n",
      "Test Loss: 0.0842\n",
      "Test Accuracy: 98.10%\n",
      "Test Accuracy: 98.10%\n",
      "Average Loss: 0.0157\n",
      "Accuracy: 99.47%\n",
      "Test Loss: 0.0762\n",
      "Test Accuracy: 98.39%\n",
      "Test Accuracy: 98.39%\n",
      "Average Loss: 0.0144\n",
      "Accuracy: 99.50%\n",
      "Test Loss: 0.0869\n",
      "Test Accuracy: 98.05%\n",
      "Test Accuracy: 98.05%\n",
      "Average Loss: 0.0147\n",
      "Accuracy: 99.53%\n",
      "Test Loss: 0.0824\n",
      "Test Accuracy: 98.09%\n",
      "Test Accuracy: 98.09%\n",
      "Average Loss: 0.0141\n",
      "Accuracy: 99.52%\n",
      "Test Loss: 0.0879\n",
      "Test Accuracy: 98.19%\n",
      "Test Accuracy: 98.19%\n",
      "Average Loss: 0.0149\n",
      "Accuracy: 99.51%\n",
      "Test Loss: 0.0835\n",
      "Test Accuracy: 98.27%\n",
      "Test Accuracy: 98.27%\n",
      "Average Loss: 0.0128\n",
      "Accuracy: 99.57%\n",
      "Test Loss: 0.0827\n",
      "Test Accuracy: 98.27%\n",
      "Test Accuracy: 98.27%\n",
      "Average Loss: 0.0134\n",
      "Accuracy: 99.49%\n",
      "Test Loss: 0.0905\n",
      "Test Accuracy: 98.11%\n",
      "Test Accuracy: 98.11%\n",
      "Average Loss: 0.0157\n",
      "Accuracy: 99.50%\n",
      "Test Loss: 0.0708\n",
      "Test Accuracy: 98.48%\n",
      "Test Accuracy: 98.48%\n",
      "Average Loss: 0.0112\n",
      "Accuracy: 99.62%\n",
      "Test Loss: 0.0814\n",
      "Test Accuracy: 98.29%\n",
      "Test Accuracy: 98.29%\n",
      "Average Loss: 0.0119\n",
      "Accuracy: 99.57%\n",
      "Test Loss: 0.0816\n",
      "Test Accuracy: 98.33%\n",
      "Test Accuracy: 98.33%\n",
      "Average Loss: 0.0142\n",
      "Accuracy: 99.53%\n",
      "Test Loss: 0.0839\n",
      "Test Accuracy: 98.38%\n",
      "Test Accuracy: 98.38%\n",
      "Average Loss: 0.0115\n",
      "Accuracy: 99.60%\n",
      "Test Loss: 0.0795\n",
      "Test Accuracy: 98.35%\n",
      "Test Accuracy: 98.35%\n",
      "Average Loss: 0.0078\n",
      "Accuracy: 99.74%\n",
      "Test Loss: 0.0831\n",
      "Test Accuracy: 98.42%\n",
      "Test Accuracy: 98.42%\n",
      "Average Loss: 0.0141\n",
      "Accuracy: 99.51%\n",
      "Test Loss: 0.0845\n",
      "Test Accuracy: 98.45%\n",
      "Test Accuracy: 98.45%\n",
      "Average Loss: 0.0095\n",
      "Accuracy: 99.69%\n",
      "Test Loss: 0.0806\n",
      "Test Accuracy: 98.40%\n",
      "Test Accuracy: 98.40%\n",
      "Average Loss: 0.0114\n",
      "Accuracy: 99.62%\n",
      "Test Loss: 0.0942\n",
      "Test Accuracy: 98.28%\n",
      "Test Accuracy: 98.28%\n",
      "Average Loss: 0.0102\n",
      "Accuracy: 99.65%\n",
      "Test Loss: 0.0876\n",
      "Test Accuracy: 98.49%\n",
      "Test Accuracy: 98.49%\n",
      "Average Loss: 0.0101\n",
      "Accuracy: 99.65%\n",
      "Test Loss: 0.0881\n",
      "Test Accuracy: 98.44%\n",
      "Test Accuracy: 98.44%\n",
      "Average Loss: 0.0105\n",
      "Accuracy: 99.66%\n",
      "Test Loss: 0.0944\n",
      "Test Accuracy: 98.25%\n",
      "Test Accuracy: 98.25%\n",
      "Vraie étiquette: 6\n",
      "Prédiction: 6\n",
      "Logits bruts: tensor([-16.6424, -16.0793, -33.3796, -41.4744, -11.9530, -10.6537,  25.7916,\n",
      "        -50.5050,  -3.8671, -21.3944], device='mps:0')\n",
      "Probabilités: tensor([3.7252e-19, 6.5421e-19, 2.0058e-26, 6.1197e-30, 4.0524e-17, 1.4860e-16,\n",
      "        1.0000e+00, 7.3251e-34, 1.3164e-13, 3.2165e-21], device='mps:0')\n",
      "✅ Modèle ONNX exporté : mnist_cnn.onnx\n"
     ]
    }
   ],
   "source": [
    "writer = SummaryWriter()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(train_loader: DataLoader, model: nn.Module, criterion: nn.Module, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X = X.to(device).float()\n",
    "        y = y.to(device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = criterion(y_pred, y)\n",
    "        batch_size = X.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        _, predicted = torch.max(y_pred, 1)\n",
    "        correct_predictions += (predicted == y).sum().item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    average_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    print(f\"Average Loss: {average_loss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    writer.add_scalar('Loss/train', average_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/train', accuracy, epoch)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model: nn.Module,\n",
    "         dataloader: torch.utils.data.DataLoader,\n",
    "         criterion: nn.Module,\n",
    "         device: torch.device = torch.device(\"cpu\")) -> tuple[float, float]:\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs = inputs.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    test_loss = running_loss / total\n",
    "    accuracy = 100.0 * correct / total\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return test_loss, accuracy\n",
    "\n",
    "for epoch in range(50):\n",
    "    train(train_dataloader, model, criterion, optimizer)\n",
    "    test_loss, test_accuracy = test(model, test_dataloader, criterion, device)\n",
    "    writer.add_scalar('Loss/test', test_loss, epoch)\n",
    "    writer.add_scalar('Accuracy/test', test_accuracy, epoch)\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(test_accuracy))\n",
    "\n",
    "writer.close()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_image, test_label = next(iter(test_dataloader))\n",
    "    test_image = test_image[0:1].to(device)\n",
    "    \n",
    "    logits = model(test_image)\n",
    "    probabilities = F.softmax(logits, dim=1)\n",
    "    predicted = torch.argmax(logits, dim=1)\n",
    "    \n",
    "    print(f\"Vraie étiquette: {test_label[0]}\")\n",
    "    print(f\"Prédiction: {predicted[0]}\")\n",
    "    print(f\"Logits bruts: {logits[0]}\")\n",
    "    print(f\"Probabilités: {probabilities[0]}\")\n",
    "\n",
    "model_cpu = model.to('cpu')\n",
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_cpu,\n",
    "    dummy_input,\n",
    "    \"mnist_cnn.onnx\",\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}},\n",
    "    opset_version=11\n",
    ")\n",
    "\n",
    "print(\"✅ Modèle ONNX exporté : mnist_cnn.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
